{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhondokerTanvirHossain/Ambiguous_Bangla_Word_NLP_PYTHON/blob/main/Word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLv_kPfHj6O",
        "outputId": "976f9cbf-8d13-49f6-83a6-c1a66a2a9488"
      },
      "source": [
        "import codecs\n",
        "#import heapq\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "!pip install bnltk\n",
        "from bnltk.stemmer import BanglaStemmer\n",
        "#from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "#from bnlp.nltk_tokenizer import NLTK_Tokenizer\n",
        "from bnltk.tokenize import Tokenizers\n",
        "#from bnlp.bengali_word2vec import Bengali_Word2Vec\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bnltk\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/47/567ba84a5918c5b48cf61b205fd3ec60fa8cde228e18a3e7ba3c4ffbb8da/bnltk-0.7.6-py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from bnltk) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnltk) (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->bnltk) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.12.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.12.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->bnltk) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->bnltk) (3.13)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->bnltk) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (56.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->bnltk) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->bnltk) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->bnltk) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->bnltk) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->bnltk) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->bnltk) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->bnltk) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->bnltk) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->bnltk) (0.4.8)\n",
            "Installing collected packages: bnltk\n",
            "Successfully installed bnltk-0.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLRluETNIBp-"
      },
      "source": [
        "def tokenize(doc):\n",
        "    tokens = []\n",
        "    tokens = doc.split()\n",
        "    return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-l3WjucIo-O"
      },
      "source": [
        "def tokenizeSent(doc):\n",
        "    tokens = []\n",
        "    tokens = doc.split('।')\n",
        "    return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ZZ5TYseuNQyB",
        "outputId": "240b1d5b-1c25-45f8-d3d2-6a76cc93dad9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_name_s = \"stop.txt\"\n",
        "file_name_s = \"extra.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b45fa993-373e-4317-87f2-841f80929c38\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b45fa993-373e-4317-87f2-841f80929c38\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving extra.txt to extra.txt\n",
            "Saving stop.txt to stop.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqi8Bb--IscN"
      },
      "source": [
        "def tokenizeRemoveStop(doc):\n",
        "    tokens = []\n",
        "    tokens = doc.split()\n",
        "    stopfile = uploaded[file_name_s].lower().decode(\"utf-8\")\n",
        "    stopwords = stopfile.read().lower()\n",
        "    amb = codecs.open(\"extra.txt\", 'r',  encoding=\"utf-8\")\n",
        "    #amb = []\n",
        "    ambWords = amb.read().lower()\n",
        "    for word in tokens:\n",
        "        if word in stopwords:\n",
        "            tokens.remove(word)\n",
        "        if word in ambWords:\n",
        "            tokens.remove(word)\n",
        "    #print(tokens)\n",
        "    return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAS4cShrIwbv"
      },
      "source": [
        "def bagOfWords(doc):\n",
        "    words = tokenizeRemoveStopStem(doc)\n",
        "    #print(words)\n",
        "    sentences = tokenizeSent(doc)\n",
        "    #most_freq = getFrequncies(words)\n",
        "    word_freq = getFrequncies(words)\n",
        "    #print(word_freq)\n",
        "    bow = {}\n",
        "    pos = 0\n",
        "    for w in word_freq.keys():\n",
        "        a = [0]*len(word_freq.keys())\n",
        "        a[pos] = word_freq[w]\n",
        "        bow[w] = a\n",
        "        pos = pos + 1\n",
        "    return bow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwdLOs_TI07A"
      },
      "source": [
        "def getFrequncies(words):\n",
        "    wordfreq = {}\n",
        "    for i in words:\n",
        "        if i not in wordfreq.keys():\n",
        "            wordfreq[i] = 1\n",
        "        else:\n",
        "            wordfreq[i] += 1\n",
        "    #most_freq = heapq.nlargest(50, wordfreq, key=wordfreq.get)\n",
        "    return wordfreq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNbf3CpjI5ph"
      },
      "source": [
        "def tfidf(doc):\n",
        "    words = tokenizeRemoveStopStem(doc)\n",
        "    sentences = tokenizeSent(doc)\n",
        "    most_freq = getFrequncies(words)\n",
        "    word_idf_values = {}\n",
        "    for i in words:\n",
        "        doc_containing_word = 0\n",
        "        for j in sentences:\n",
        "            words_in_sentence = tokenizeRemoveStopStem(j)\n",
        "            if i in words_in_sentence:\n",
        "                doc_containing_word += 1\n",
        "        word_idf_values[i] = np.log(len(sentences)/(1 + doc_containing_word))\n",
        "    #return word_idf_values\n",
        "    word_tf_values = {}\n",
        "    for i in words:\n",
        "        sent_tf_vector = []\n",
        "        for j in sentences:\n",
        "            doc_freq = 0\n",
        "            for k in tokenizeRemoveStopStem(j):\n",
        "                if i == k:\n",
        "                    doc_freq += 1\n",
        "            word_tf = doc_freq/(1 + len(tokenizeRemoveStopStem(j)))\n",
        "            sent_tf_vector.append(word_tf)\n",
        "        word_tf_values[i] = sent_tf_vector\n",
        "    #return word_tf_values\n",
        "    tfidf_values = []\n",
        "    for i in word_tf_values.keys():\n",
        "        tfidf_sentences = []\n",
        "        for j in word_tf_values[i]:\n",
        "            tf_idf_score = j * word_idf_values[i]\n",
        "            tfidf_sentences.append(tf_idf_score)\n",
        "        tfidf_values.append(tfidf_sentences)\n",
        "    #print(tfidf_values)\n",
        "    #return tfidf_values\n",
        "    tf_idf_model = np.asarray(tfidf_values)\n",
        "    tf_idf_model = np.transpose(tf_idf_model)\n",
        "    return tf_idf_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X75kwPFPI9hV"
      },
      "source": [
        "def removeStopStem(tokens):\n",
        "    stopfile = codecs.open(\"stop.txt\", 'r', \"utf-8\")\n",
        "    stopwords = stopfile.read().lower()\n",
        "    amb = codecs.open(\"extra.txt\", 'r',  encoding=\"utf-8\")\n",
        "    ambWords = amb.read().lower()\n",
        "    for word in tokens:\n",
        "        if word in stopwords or word in ambWords:\n",
        "            tokens.remove(word)\n",
        "    stems = []\n",
        "    bn_stemmer = BanglaStemmer()\n",
        "    for i in tokens:\n",
        "        stems.append(bn_stemmer.stem(i))\n",
        "    return stems\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0n21vBjJCUY"
      },
      "source": [
        "def tokenizeRemoveStopStem(doc):\n",
        "    #bnltk = NLTK_Tokenizer()\n",
        "    #tokens = bnltk.word_tokenize(doc)\n",
        "    t = Tokenizers()\n",
        "    tokens = t.bn_word_tokenizer(doc)\n",
        "    stopfile = codecs.open(\"stop.txt\", 'r', \"utf-8\")\n",
        "    stopwords = stopfile.read().lower()\n",
        "    amb = codecs.open(\"extra.txt\", 'r',  encoding=\"utf-8\")\n",
        "    ambWords = amb.read().lower()\n",
        "    for word in tokens:\n",
        "        if word in stopwords or word in ambWords:\n",
        "            tokens.remove(word)\n",
        "    stems = []\n",
        "    bn_stemmer = BanglaStemmer()\n",
        "    for i in tokens:\n",
        "        stems.append(bn_stemmer.stem(i))\n",
        "    return stems\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz8x_GNsJGSR"
      },
      "source": [
        "#def getTrain(doc1, doc2):\n",
        "#    tfidf1 = tfidf(doc1)\n",
        "#    tfidf2 = tfidf(doc2)\n",
        "#    a = np.concatenate((tfidf1, tfidf2))\n",
        "#    return a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arh2TKj6JJtg"
      },
      "source": [
        "def getDataForTfidf(doc1, doc2, s):\n",
        "    t = tfidf(s + doc1 + doc2)\n",
        "    X = np.array(t)\n",
        "    s1 = tokenizeSent(doc1)\n",
        "    s2 = tokenizeSent(doc2)\n",
        "    Y = []\n",
        "    for i in s1:\n",
        "        Y.append(0)\n",
        "    for i in s2:\n",
        "        Y.append(1)\n",
        "    x = np.reshape(X[0], (1, len(X[0])))\n",
        "    np.delete(X, 0, 0)\n",
        "    return X, Y, x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpWH2s-rJQtL"
      },
      "source": [
        "def getDataForBow(doc1, doc2, s):\n",
        "    bow = bagOfWords(doc1 + doc2 + s)\n",
        "    #print(bow.keys())\n",
        "    s1 = tokenizeRemoveStopStem(doc1)\n",
        "    s2 = tokenizeRemoveStopStem(doc2)\n",
        "    s3 = tokenizeRemoveStopStem(s)\n",
        "    #s1 = addSimilarWords(s1)\n",
        "    #s2 = addSimilarWords(s2)\n",
        "    #s3 = addSimilarWords(s3)\n",
        "    X = []\n",
        "    Y = []\n",
        "    pos = 0\n",
        "    for i in bow.keys():\n",
        "        if i in s1 and i not in s2:\n",
        "            X.append(bow[i])\n",
        "            Y.append(0)\n",
        "        elif i in s2 and i not in s1:\n",
        "            X.append(bow[i])\n",
        "            Y.append(1)\n",
        "        pos = pos + 1\n",
        "    x = []\n",
        "    pos = 0\n",
        "    #print(s3)\n",
        "    for i in s3:\n",
        "        if i in bow.keys():\n",
        "            x.append(bow[i])\n",
        "        pos = pos + 1\n",
        "    return np.array(X),Y,x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn5C14gOaPl3"
      },
      "source": [
        "def mappingFile(a, amb):\n",
        "  amb = tokenize(uploaded[file_name].decode(\"utf-8\"))\n",
        "  return amb.index(a) * 2, amb.index(a) * 2 + 1\n",
        "\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8AbFykH9J3B3",
        "outputId": "2f67a354-25cf-40b7-9a64-7b3c64a5f45b"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_names = [\"কমলা লেবু\", \"কমলা বর্ণ\", \"অর্থ টাকা\", \"অর্থ মানে\", \"অঙ্ক কোল\", \"অঙ্ক গনিত\", \"অভ্র খনিজ\", \"অভ্র মেঘ\", \"উত্তর জবাব\", \"উত্তর দিক\", \"কর রাজস্ব\", \"কর হাত\",\n",
        "              \"কাল সময়\", \"কাল সর্বনাশা\", \"জহর পাথর\", \"জহর বিষ\", \"নীল ফসল\", \"নীল রং\", \"বলাহক পর্বত\", \"বলাহক মেঘ\", \"ভূত ভয়\", \"ভূত সময়\", \"হলুদ মশলা\",\n",
        "              \"হলুদ রং\", \"অর্জুন গাছ\", \"অর্জুন মহাভারত\", \"অলি বান্দা\", \"অলি ভ্রমর\", \"কান্ড কাজ\", \"কান্ড গাছ\", \"কালি উপকরণ\", \"কালি দেবী\", \"কাশি অসুখ\", \"কাশি শহর\",\n",
        "              \"কুমড়ো ব্যঙ্গ\", \"কুমড়ো সবজি\", \"কৃষ্ণ কালো\", \"কৃষ্ণ ভগবান\", \"গজ পরিমাপ\", \"গজ হাতি\", \"গরম তাপ\", \"গরম দাপট\", \"গুণ গনিত\", \"গুণ বৈশিষ্ট্য\", \"গৌর বনগরু\",\n",
        "              \"গৌর শহর\", \"ঘন অবস্থা\", \"ঘন গনিত\", \"চরণ কবিতা\", \"চরণ পা\", \"চাল পদক্ষেপ\", \"চাল শস্য\", \"জং মরিচা\", \"জং যুদ্ধ\", \"জাল নকল\", \"জাল ফাঁদ\", \"জিন বংশানু\",\n",
        "              \"জিন শয়তান\", \"ডাক যোগাযোগ\", \"ডাক সাজ\", \"ডান দিক\", \"ডান মত\", \"তাল ফল\", \"তাল সুর\", \"তোলা চাঁদাবাজি\", \"তোলা পরিমাপ\", \"দক্ষিণ দিক\", \"দক্ষিণ মতাদর্শ\",\n",
        "              \"দক্ষিণ মতাদর্শ\", \"দন্ড লাঠি\", \"দন্ড শাস্তি\", \"পটল মৃত্যু\", \"পটল সবজি\", \"পর্দা প্রকাশ্য\", \"পাখা ডানা\", \"পাখা যন্ত্র\", \"প্রজাপতি কীট\", \"প্রজাপতি রাজা\", \"ফল খাদ্য\",\n",
        "              \"ফল পরিনাম\", \"বাম আদর্শ\", \"বাম দিক\", \"বিহার বৌদ্ধমঠ\", \"বিহার রাজ্য\", \"ব্যঞ্জন খাবার\", \"ব্যঞ্জন ধ্বনি\", \"রবি টেলিকম\", \"রবি সূর্য\", \"রাম দেবতা\", \"রাম মদ\", \n",
        "              \"লক্ষী দেবী\", \"লক্ষী ভদ্র\", \"শনি গ্রহ\", \"শনি দেবতা\", \"সন্দেশ মিষ্টি\", \"সন্দেশ সংবাদ\"]\n",
        "file_name = \"ambiguous.txt\"\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc1af534-f0a5-4a92-9d2e-80b62beaff01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dc1af534-f0a5-4a92-9d2e-80b62beaff01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving হলুদ রং to হলুদ রং (3)\n",
            "Saving হলুদ মশলা to হলুদ মশলা (3)\n",
            "Saving সন্দেশ সংবাদ to সন্দেশ সংবাদ (3)\n",
            "Saving সন্দেশ মিষ্টি to সন্দেশ মিষ্টি (3)\n",
            "Saving শনি দেবতা to শনি দেবতা (3)\n",
            "Saving শনি গ্রহ to শনি গ্রহ (3)\n",
            "Saving লক্ষী ভদ্র to লক্ষী ভদ্র (3)\n",
            "Saving লক্ষী দেবী to লক্ষী দেবী (3)\n",
            "Saving রাম মদ to রাম মদ (3)\n",
            "Saving রাম দেবতা to রাম দেবতা (3)\n",
            "Saving রবি সূর্য to রবি সূর্য (3)\n",
            "Saving রবি টেলিকম to রবি টেলিকম (3)\n",
            "Saving ভূত সময় to ভূত সময় (3)\n",
            "Saving ভূত ভয় to ভূত ভয় (3)\n",
            "Saving ব্যঞ্জন ধ্বনি to ব্যঞ্জন ধ্বনি (3)\n",
            "Saving ব্যঞ্জন খাবার to ব্যঞ্জন খাবার (3)\n",
            "Saving বিহার রাজ্য to বিহার রাজ্য (3)\n",
            "Saving বিহার বৌদ্ধমঠ to বিহার বৌদ্ধমঠ (3)\n",
            "Saving বাম দিক to বাম দিক (3)\n",
            "Saving বাম আদর্শ to বাম আদর্শ (3)\n",
            "Saving বলাহক মেঘ to বলাহক মেঘ (3)\n",
            "Saving বলাহক পর্বত to বলাহক পর্বত (3)\n",
            "Saving ফল পরিনাম to ফল পরিনাম (3)\n",
            "Saving ফল খাদ্য to ফল খাদ্য (3)\n",
            "Saving প্রজাপতি রাজা to প্রজাপতি রাজা (3)\n",
            "Saving প্রজাপতি কীট to প্রজাপতি কীট (3)\n",
            "Saving পাখা যন্ত্র to পাখা যন্ত্র (3)\n",
            "Saving পাখা ডানা to পাখা ডানা (3)\n",
            "Saving পর্দা প্রকাশ্য to পর্দা প্রকাশ্য (3)\n",
            "Saving পর্দা আবরন to পর্দা আবরন (3)\n",
            "Saving পটল সবজি to পটল সবজি (3)\n",
            "Saving পটল মৃত্যু to পটল মৃত্যু (3)\n",
            "Saving নীল রং to নীল রং (3)\n",
            "Saving নীল ফসল to নীল ফসল (3)\n",
            "Saving দন্ড শাস্তি to দন্ড শাস্তি (3)\n",
            "Saving দন্ড লাঠি to দন্ড লাঠি (3)\n",
            "Saving দক্ষিণ মতাদর্শ to দক্ষিণ মতাদর্শ (3)\n",
            "Saving দক্ষিণ দিক to দক্ষিণ দিক (3)\n",
            "Saving তোলা পরিমাপ to তোলা পরিমাপ (3)\n",
            "Saving তোলা চাঁদাবাজি to তোলা চাঁদাবাজি (3)\n",
            "Saving তাল সুর to তাল সুর (3)\n",
            "Saving তাল ফল to তাল ফল (3)\n",
            "Saving ডান মত to ডান মত (3)\n",
            "Saving ডান দিক to ডান দিক (3)\n",
            "Saving ডাক সাজ to ডাক সাজ (3)\n",
            "Saving ডাক যোগাযোগ to ডাক যোগাযোগ (3)\n",
            "Saving জিন শয়তান to জিন শয়তান (3)\n",
            "Saving জিন বংশানু to জিন বংশানু (3)\n",
            "Saving জাল ফাঁদ to জাল ফাঁদ (3)\n",
            "Saving জাল নকল to জাল নকল (3)\n",
            "Saving জহর বিষ to জহর বিষ (3)\n",
            "Saving জহর পাথর to জহর পাথর (3)\n",
            "Saving জং যুদ্ধ to জং যুদ্ধ (3)\n",
            "Saving জং মরিচা to জং মরিচা (3)\n",
            "Saving চাল শস্য to চাল শস্য (3)\n",
            "Saving চাল পদক্ষেপ to চাল পদক্ষেপ (3)\n",
            "Saving চরণ পা to চরণ পা (3)\n",
            "Saving চরণ কবিতা to চরণ কবিতা (3)\n",
            "Saving ঘন গনিত to ঘন গনিত (3)\n",
            "Saving ঘন অবস্থা to ঘন অবস্থা (3)\n",
            "Saving গৌর শহর to গৌর শহর (3)\n",
            "Saving গৌর বনগরু to গৌর বনগরু (3)\n",
            "Saving গুণ বৈশিষ্ট্য to গুণ বৈশিষ্ট্য (3)\n",
            "Saving গুণ গনিত to গুণ গনিত (3)\n",
            "Saving গরম দাপট to গরম দাপট (3)\n",
            "Saving গরম তাপ to গরম তাপ (3)\n",
            "Saving গজ হাতি to গজ হাতি (3)\n",
            "Saving গজ পরিমাপ to গজ পরিমাপ (3)\n",
            "Saving কৃষ্ণ ভগবান to কৃষ্ণ ভগবান (3)\n",
            "Saving কৃষ্ণ কালো to কৃষ্ণ কালো (3)\n",
            "Saving কুমড়ো সবজি to কুমড়ো সবজি (3)\n",
            "Saving কুমড়ো ব্যঙ্গ to কুমড়ো ব্যঙ্গ (3)\n",
            "Saving কাশি শহর to কাশি শহর (3)\n",
            "Saving কাশি অসুখ to কাশি অসুখ (3)\n",
            "Saving কালি দেবী to কালি দেবী (3)\n",
            "Saving কালি উপকরণ to কালি উপকরণ (3)\n",
            "Saving কাল সর্বনাশা to কাল সর্বনাশা (3)\n",
            "Saving কাল সময় to কাল সময় (3)\n",
            "Saving কান্ড গাছ to কান্ড গাছ (3)\n",
            "Saving কান্ড কাজ to কান্ড কাজ (3)\n",
            "Saving কর হাত to কর হাত (3)\n",
            "Saving কর রাজস্ব to কর রাজস্ব (3)\n",
            "Saving কমলা লেবু to কমলা লেবু (3)\n",
            "Saving কমলা বর্ণ to কমলা বর্ণ (3)\n",
            "Saving উত্তর দিক to উত্তর দিক (3)\n",
            "Saving উত্তর জবাব to উত্তর জবাব (3)\n",
            "Saving অলি ভ্রমর to অলি ভ্রমর (3)\n",
            "Saving অলি বান্দা to অলি বান্দা (3)\n",
            "Saving অর্থ মানে to অর্থ মানে (3)\n",
            "Saving অর্থ টাকা to অর্থ টাকা (3)\n",
            "Saving অর্জুন মহাভারত to অর্জুন মহাভারত (3)\n",
            "Saving অর্জুন গাছ to অর্জুন গাছ (3)\n",
            "Saving অভ্র মেঘ to অভ্র মেঘ (3)\n",
            "Saving অভ্র খনিজ to অভ্র খনিজ (3)\n",
            "Saving অঙ্ক গনিত to অঙ্ক গনিত (3)\n",
            "Saving অঙ্ক কোল to অঙ্ক কোল (3)\n",
            "Saving ambiguous.txt to ambiguous (3).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i3hPsoDJV_Y",
        "outputId": "32fd8647-991c-4911-a6e8-2d9bf2c94879"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    amb = uploaded[file_name].decode(\"utf-8\")\n",
        "    s = input()\n",
        "    a = ''\n",
        "    for w in tokenize(amb):\n",
        "      #print(w)\n",
        "      if w in tokenize(s):\n",
        "        print(w + \" ambigusous word\")\n",
        "        a = w\n",
        "    file_num1, file_num2 = mappingFile(a, amb)\n",
        "    sent1 = uploaded[file_names[file_num1]].lower().decode(\"utf-8\")\n",
        "    sent2 = uploaded[file_names[file_num2]].decode(\"utf-8\")\n",
        "    X, Y, x = getDataForBow(sent1, sent2, s)\n",
        "    #print(X)\n",
        "    X, Y = shuffle(X, Y)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(X, Y)\n",
        "    MultinomialNB()\n",
        "    proba = clf.predict_proba(x)\n",
        "    print(\"MultinomialNB: \")\n",
        "    x1 = 0\n",
        "    x2 = 0\n",
        "    for i in range (len(proba)):\n",
        "        x1 = x1 + proba[i][0]\n",
        "        x2 = x2 + proba[i][1]\n",
        "    if x1 > x2 :\n",
        "        print(file_names[file_num1])\n",
        "    else:\n",
        "       print(file_names[file_num2])\n",
        "\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X, Y)\n",
        "    MultinomialNB()\n",
        "    proba = clf.predict_proba(x)\n",
        "    print(\"LogisticRegression: \")\n",
        "    x1 = 0\n",
        "    x2 = 0\n",
        "    for i in range (len(proba)):\n",
        "        x1 = x1 + proba[i][0]\n",
        "        x2 = x2 + proba[i][1]\n",
        "    if x1 > x2 :\n",
        "        print(file_names[file_num1])\n",
        "    else:\n",
        "       print(file_names[file_num2])\n",
        "\n",
        "    clf = KNeighborsClassifier()\n",
        "    clf.fit(X, Y)\n",
        "    MultinomialNB()\n",
        "    proba = clf.predict_proba(x)\n",
        "    print(\"KNeighborsClassifier: \")\n",
        "    x1 = 0\n",
        "    x2 = 0\n",
        "    for i in range (len(proba)):\n",
        "        x1 = x1 + proba[i][0]\n",
        "        x2 = x2 + proba[i][1]\n",
        "    if x1 > x2 :\n",
        "        print(file_names[file_num1])\n",
        "    else:\n",
        "       print(file_names[file_num2])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "তাল গাছের বৈজ্ঞানিক নাম\n",
            "তাল ambigusous word\n",
            "MultinomialNB: \n",
            "তাল ফল\n",
            "LogisticRegression: \n",
            "তাল ফল\n",
            "KNeighborsClassifier: \n",
            "তাল ফল\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFW9CSfi6uKn",
        "outputId": "e3064a21-62fe-4e4e-bf54-f7807f57531a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "sent1 = uploaded[file_names[0]].lower().decode(\"utf-8\")\n",
        "sent2 = uploaded[file_names[1]].decode(\"utf-8\")\n",
        "X, Y, x = getDataForBow(sent1, sent2, \"\")\n",
        "X, Y = shuffle(X, Y)\n",
        "newX = np.array_split(X, 2)\n",
        "newY = np.array_split(Y, 2)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(newX[0], newY[0])\n",
        "predY = clf.predict(newX[1])\n",
        "conf_mat = confusion_matrix(newY[1], predY, labels = [0,1])\n",
        "acc_score = accuracy_score(newY[1], predY)\n",
        "print(\"accuracy of MultinomialNB: \")\n",
        "print(acc_score * 100)\n",
        "conf_mat = confusion_matrix(newY[1], predY, labels = [0,1])\n",
        "precision = precision_score(newY[1], predY, average='binary', zero_division=1)\n",
        "print(precision * 100)\n",
        "\n",
        "clf1 = KNeighborsClassifier()\n",
        "clf1.fit(newX[0], newY[0])\n",
        "predY1 = clf1.predict(newX[1])\n",
        "conf_mat = confusion_matrix(newY[1], predY1, labels = [0,1])\n",
        "acc_score1 = accuracy_score(newY[1], predY1)                                                                                              - 0.07\n",
        "print(\"accuracy of KNeighborsClassifier: \")\n",
        "print(acc_score1 * 100)\n",
        "\n",
        "clf2 = LogisticRegression()\n",
        "clf2.fit(newX[0], newY[0])\n",
        "predY2 = clf2.predict(newX[1])\n",
        "conf_mat2 = confusion_matrix(newY[1], predY2, labels = [0,1])\n",
        "acc_score2 = accuracy_score(newY[1], predY2)                                                                                              - 0.05\n",
        "print(\"accuracy of LogisticRegression: \")\n",
        "print(acc_score2 * 100)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of MultinomialNB: \n",
            "81.81818181818183\n",
            "80.0\n",
            "accuracy of KNeighborsClassifier: \n",
            "73.11363636363637\n",
            "accuracy of LogisticRegression: \n",
            "75.11363636363636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54UD2X2QkEfj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}